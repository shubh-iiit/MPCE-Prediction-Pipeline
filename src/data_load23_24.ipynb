{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rSVIJweOJq2O","executionInfo":{"status":"ok","timestamp":1749976989885,"user_tz":-330,"elapsed":46716,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}},"outputId":"b85711c2-2647-45a6-e2e6-9ed2c77ba1a7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install pandas scikit-learn pyarrow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jO-HV6tYKob9","executionInfo":{"status":"ok","timestamp":1749887425638,"user_tz":-330,"elapsed":9489,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}},"outputId":"dd5534c8-0f99-4158-ac8a-9789a6cb7418"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (18.1.0)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Step 1: Load the Parquet files\n","hh_df = pd.read_parquet('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/HH_Level_data.parquet')\n","person_df = pd.read_parquet('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/Person_Level_Data.parquet')\n","\n","# Step 2: Create 80:20 train-test split for each\n","hh_train, hh_test = train_test_split(hh_df, test_size=0.2, random_state=42, shuffle=True)\n","person_train, person_test = train_test_split(person_df, test_size=0.2, random_state=42, shuffle=True)\n","\n","# Step 3: Save the splits as CSV\n","hh_train.to_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/hh_train.csv', index=False)\n","hh_test.to_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/hh_test.csv', index=False)\n","person_train.to_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/person_train.csv', index=False)\n","person_test.to_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/person_test.csv', index=False)\n","\n","print(\"All files saved: hh_train.csv, hh_test.csv, person_train.csv, person_test.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oyLSc_bGLNzj","executionInfo":{"status":"ok","timestamp":1749715667526,"user_tz":-330,"elapsed":17425,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}},"outputId":"cefae9d5-ef77-480a-be11-e89f3aae5b56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… All files saved: hh_train.csv, hh_test.csv, person_train.csv, person_test.csv\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11404,"status":"ok","timestamp":1749887449062,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"},"user_tz":-330},"id":"v_Mgziw5WTqU","outputId":"022d7c05-9ea3-46c4-daac-879e742a7a36"},"outputs":[{"output_type":"stream","name":"stdout","text":["Household Train Data Shape: (209562, 36)\n","Person Train Data Shape: (885776, 16)\n","Household Test Data Shape: (52391, 36)\n","Person Test Data Shape: (221445, 16)\n","\n","Missing Values in Household Train Data:\n","HH_ID                                                    0\n","Sector                                                   0\n","State                                                    0\n","NSS-Region                                               0\n","District                                                 0\n","Household Type                                           0\n","Religion of the head of the household                    0\n","Social Group of the head of the household                0\n","HH Size (For FDQ)                                        0\n","NCO_3D                                               20779\n","NIC_5D                                               20779\n","Is_online_Clothing_Purchased_Last365                160714\n","Is_online_Footwear_Purchased_Last365                179428\n","Is_online_Furniture_fixturesPurchased_Last365       209110\n","Is_online_Mobile_Handset_Purchased_Last365          206824\n","Is_online_Personal_Goods_Purchased_Last365          202138\n","Is_online_Recreation_Goods_Purchased_Last365        208426\n","Is_online_Household_Appliances_Purchased_Last365    207294\n","Is_online_Crockery_Utensils_Purchased_Last365       206991\n","Is_online_Sports_Goods_Purchased_Last365            207380\n","Is_online_Medical_Equipment_Purchased_Last365       208779\n","Is_online_Bedding_Purchased_Last365                 204908\n","Is_HH_Have_Television                                63925\n","Is_HH_Have_Radio                                    205314\n","Is_HH_Have_Laptop_PC                                193058\n","Is_HH_Have_Mobile_handset                             5122\n","Is_HH_Have_Bicycle                                  128214\n","Is_HH_Have_Motorcycle_scooter                        82754\n","Is_HH_Have_Motorcar_jeep_van                        191675\n","Is_HH_Have_Trucks                                   209382\n","Is_HH_Have_Animal_cart                              208305\n","Is_HH_Have_Refrigerator                             107803\n","Is_HH_Have_Washing_machine                          159100\n","Is_HH_Have_Airconditioner_aircooler                 148054\n","Weight                                                   0\n","TotalExpense                                             0\n","dtype: int64\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.ensemble import RandomForestRegressor\n","#import xgboost as xgb\n","\n","# Load the data\n","# Replace with your actual file paths\n","hh_train = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/hh_train.csv')\n","person_train = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/person_train.csv')\n","hh_test = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/hh_test.csv')\n","person_test = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/person_test.csv')\n","\n","# Basic information about the datasets\n","print(\"Household Train Data Shape:\", hh_train.shape)\n","print(\"Person Train Data Shape:\", person_train.shape)\n","print(\"Household Test Data Shape:\", hh_test.shape)\n","print(\"Person Test Data Shape:\", person_test.shape)\n","\n","\n","\n","# Check for missing values\n","print(\"\\nMissing Values in Household Train Data:\")\n","print(hh_train.isnull().sum())\n"]},{"cell_type":"markdown","metadata":{"id":"NSI0ipmcnKyg"},"source":["# New Section"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"1uWCh84pWTqW","executionInfo":{"status":"ok","timestamp":1749887465667,"user_tz":-330,"elapsed":2824,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","# Load the data\n","# Replace with your actual file paths\n","hh_train = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/hh_train.csv')\n","person_train = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/person_train.csv')\n","hh_test = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/hh_test.csv')\n","person_test = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/person_test.csv')\n","\n","# Define the binary categorical columns\n","binary_categorical_columns = [\n","    'Is_online_Clothing_Purchased_Last365',\n","    'Is_online_Footwear_Purchased_Last365',\n","    'Is_online_Furniture_fixturesPurchased_Last365',\n","    'Is_online_Mobile_Handset_Purchased_Last365',\n","    'Is_online_Personal_Goods_Purchased_Last365',\n","    'Is_online_Recreation_Goods_Purchased_Last365',\n","    'Is_online_Household_Appliances_Purchased_Last365',\n","    'Is_online_Crockery_Utensils_Purchased_Last365',\n","    'Is_online_Sports_Goods_Purchased_Last365',\n","    'Is_online_Medical_Equipment_Purchased_Last365',\n","    'Is_online_Bedding_Purchased_Last365',\n","    'Is_HH_Have_Television',\n","    'Is_HH_Have_Radio',\n","    'Is_HH_Have_Laptop_PC',\n","    'Is_HH_Have_Mobile_handset',\n","    'Is_HH_Have_Bicycle',\n","    'Is_HH_Have_Motorcycle_scooter',\n","    'Is_HH_Have_Motorcar_jeep_van',\n","    'Is_HH_Have_Trucks',\n","    'Is_HH_Have_Animal_cart',\n","    'Is_HH_Have_Refrigerator',\n","    'Is_HH_Have_Washing_machine',\n","    'Is_HH_Have_Airconditioner_aircooler'\n","]\n","\n","# Fill NA values with 0 (No)\n","for column in binary_categorical_columns:\n","    if column in hh_train.columns:\n","        hh_train[column] = hh_train[column].fillna(0).astype(int)\n","    if column in hh_test.columns:\n","        hh_test[column] = hh_test[column].fillna(0).astype(int)\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"toZGYXt-XRFu","executionInfo":{"status":"ok","timestamp":1749887470507,"user_tz":-330,"elapsed":1861,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}}},"outputs":[],"source":["merged_train = pd.merge(\n","    person_train,\n","    hh_train,\n","    on='HH_ID',\n","    how='inner'  # Only keep records that exist in both datasets\n",")\n","\n","# For test data\n","merged_test = pd.merge(\n","    person_test,\n","    hh_test,\n","    on='HH_ID',\n","    how='inner'  # Only keep records that exist in both datasets\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"wkas0holhimM","executionInfo":{"status":"ok","timestamp":1749887532365,"user_tz":-330,"elapsed":22030,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}}},"outputs":[],"source":["merged_train.to_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/Merged_train_data.csv', index=False)\n","merged_test.to_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/Merged_test_data.csv', index=False)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":81,"status":"ok","timestamp":1749887535554,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"},"user_tz":-330},"id":"MjP1gcDOhviq","outputId":"b5386cf4-88df-44e6-f8d9-d01376a0cb05"},"outputs":[{"output_type":"stream","name":"stdout","text":["(707703, 51)\n","(43716, 51)\n"]}],"source":["print(merged_train.shape)\n","print(merged_test.shape)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26373,"status":"ok","timestamp":1749887569517,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"},"user_tz":-330},"id":"FZEr1E1ViN8u","outputId":"e5759f0f-8a35-4b7f-94e5-09cc1c1d9a6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using merged datasets\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","\n","train_data = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/Merged_train_data.csv')\n","test_data = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/Merged_test_data.csv')\n","print(\"Using merged datasets\")\n","\n","# Column names\n","education_level_col = 'Highest educational level attained (code)'\n","education_years_col = 'Total year of education completed'\n","\n","# Function to fill missing education years based on educational level code\n","def fill_missing_education_years(df):\n","    # Create a copy to avoid modifying the original\n","    df_filled = df.copy()\n","\n","    # For each educational level code, calculate the average years of education\n","    education_level_groups = df.groupby(education_level_col)[education_years_col].mean().to_dict()\n","\n","\n","    # Fill missing values with the calculated averages\n","    missing_mask = df_filled[education_years_col].isnull()\n","\n","    # Set education years to 0 for education level codes 1 and 2\n","    level1_mask = (df_filled[education_level_col] == 1) & missing_mask\n","    level2_mask = (df_filled[education_level_col] == 2) & missing_mask\n","    df_filled.loc[level1_mask, education_years_col] = 0\n","    df_filled.loc[level2_mask, education_years_col] = 0\n","\n","    # For other education levels, use the average years for that level\n","    for level, avg_years in education_level_groups.items():\n","        if level not in [1, 2]:  # Skip levels 1 and 2 as we've already handled them\n","            level_mask = (df_filled[education_level_col] == level) & missing_mask\n","            df_filled.loc[level_mask, education_years_col] = avg_years\n","\n","    return df_filled\n","\n","# Fill missing values\n","train_data_filled = fill_missing_education_years(train_data)\n","test_data_filled = fill_missing_education_years(test_data)\n","\n","# Check if any missing values remain\n","remaining_missing_train = train_data_filled[education_years_col].isnull().sum()\n","remaining_missing_test = test_data_filled[education_years_col].isnull().sum()\n","\n","\n","train_data_filled.to_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/Merged_train_data_filled.csv', index=False)\n","test_data_filled.to_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/Merged_test_data_filled.csv', index=False)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5910,"status":"ok","timestamp":1749887578216,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"},"user_tz":-330},"id":"r2_qvlvHoIgi","outputId":"475b795a-7a16-42a8-90b0-a46ef98a97e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Missing Values in Merged Train Data:\n","HH_ID                                                                                       0\n","Person Srl No.                                                                              0\n","Relation to head (code)                                                                     0\n","Gender                                                                                      0\n","Age(in years)                                                                               0\n","Marital Status (code)                                                                       0\n","Highest educational level attained (code)                                                   0\n","Total year of education completed                                                           0\n","Whether used internet from any location during last 30 days                             24868\n","No. of days stayed away from home during last 30 days                                    1398\n","No. of meals usually taken in a day                                                      1668\n","No. of meals taken during last 30 days from school, balwadi etc.                       484133\n","No. of meals taken during last 30 days from employer as perquisites or part of wage    514221\n","No. of meals taken during last 30 days  others                                         453640\n","No. of meals taken during last 30 days on payment                                      468626\n","No. of meals taken during last 30 days at home                                           4950\n","Sector                                                                                      0\n","State                                                                                       0\n","NSS-Region                                                                                  0\n","District                                                                                    0\n","Household Type                                                                              0\n","Religion of the head of the household                                                       0\n","Social Group of the head of the household                                                   0\n","HH Size (For FDQ)                                                                           0\n","NCO_3D                                                                                  39143\n","NIC_5D                                                                                  39147\n","Is_online_Clothing_Purchased_Last365                                                        0\n","Is_online_Footwear_Purchased_Last365                                                        0\n","Is_online_Furniture_fixturesPurchased_Last365                                               0\n","Is_online_Mobile_Handset_Purchased_Last365                                                  0\n","Is_online_Personal_Goods_Purchased_Last365                                                  0\n","Is_online_Recreation_Goods_Purchased_Last365                                                0\n","Is_online_Household_Appliances_Purchased_Last365                                            0\n","Is_online_Crockery_Utensils_Purchased_Last365                                               0\n","Is_online_Sports_Goods_Purchased_Last365                                                    0\n","Is_online_Medical_Equipment_Purchased_Last365                                               0\n","Is_online_Bedding_Purchased_Last365                                                         0\n","Is_HH_Have_Television                                                                       0\n","Is_HH_Have_Radio                                                                            0\n","Is_HH_Have_Laptop_PC                                                                        0\n","Is_HH_Have_Mobile_handset                                                                   0\n","Is_HH_Have_Bicycle                                                                          0\n","Is_HH_Have_Motorcycle_scooter                                                               0\n","Is_HH_Have_Motorcar_jeep_van                                                                0\n","Is_HH_Have_Trucks                                                                           0\n","Is_HH_Have_Animal_cart                                                                      0\n","Is_HH_Have_Refrigerator                                                                     0\n","Is_HH_Have_Washing_machine                                                                  0\n","Is_HH_Have_Airconditioner_aircooler                                                         0\n","Weight                                                                                      0\n","TotalExpense                                                                                0\n","dtype: int64\n","\n","Missing Values in Merged Test Data:\n","HH_ID                                                                                       0\n","Person Srl No.                                                                              0\n","Relation to head (code)                                                                     0\n","Gender                                                                                      0\n","Age(in years)                                                                               0\n","Marital Status (code)                                                                       0\n","Highest educational level attained (code)                                                   0\n","Total year of education completed                                                           0\n","Whether used internet from any location during last 30 days                             24868\n","No. of days stayed away from home during last 30 days                                    1398\n","No. of meals usually taken in a day                                                      1668\n","No. of meals taken during last 30 days from school, balwadi etc.                       484133\n","No. of meals taken during last 30 days from employer as perquisites or part of wage    514221\n","No. of meals taken during last 30 days  others                                         453640\n","No. of meals taken during last 30 days on payment                                      468626\n","No. of meals taken during last 30 days at home                                           4950\n","Sector                                                                                      0\n","State                                                                                       0\n","NSS-Region                                                                                  0\n","District                                                                                    0\n","Household Type                                                                              0\n","Religion of the head of the household                                                       0\n","Social Group of the head of the household                                                   0\n","HH Size (For FDQ)                                                                           0\n","NCO_3D                                                                                  39143\n","NIC_5D                                                                                  39147\n","Is_online_Clothing_Purchased_Last365                                                        0\n","Is_online_Footwear_Purchased_Last365                                                        0\n","Is_online_Furniture_fixturesPurchased_Last365                                               0\n","Is_online_Mobile_Handset_Purchased_Last365                                                  0\n","Is_online_Personal_Goods_Purchased_Last365                                                  0\n","Is_online_Recreation_Goods_Purchased_Last365                                                0\n","Is_online_Household_Appliances_Purchased_Last365                                            0\n","Is_online_Crockery_Utensils_Purchased_Last365                                               0\n","Is_online_Sports_Goods_Purchased_Last365                                                    0\n","Is_online_Medical_Equipment_Purchased_Last365                                               0\n","Is_online_Bedding_Purchased_Last365                                                         0\n","Is_HH_Have_Television                                                                       0\n","Is_HH_Have_Radio                                                                            0\n","Is_HH_Have_Laptop_PC                                                                        0\n","Is_HH_Have_Mobile_handset                                                                   0\n","Is_HH_Have_Bicycle                                                                          0\n","Is_HH_Have_Motorcycle_scooter                                                               0\n","Is_HH_Have_Motorcar_jeep_van                                                                0\n","Is_HH_Have_Trucks                                                                           0\n","Is_HH_Have_Animal_cart                                                                      0\n","Is_HH_Have_Refrigerator                                                                     0\n","Is_HH_Have_Washing_machine                                                                  0\n","Is_HH_Have_Airconditioner_aircooler                                                         0\n","Weight                                                                                      0\n","TotalExpense                                                                                0\n","dtype: int64\n"]}],"source":["train_data_final = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/Merged_train_data_filled.csv')\n","test_data_final = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/Merged_test_data_filled.csv')\n","print(\"\\nMissing Values in Merged Train Data:\")\n","print(train_data_final.isnull().sum())\n","print(\"\\nMissing Values in Merged Test Data:\")\n","print(train_data_final.isnull().sum())\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68,"status":"ok","timestamp":1749887583614,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"},"user_tz":-330},"id":"jJQhgX0-sXCW","outputId":"7bed3aa2-a4fe-4c77-c103-80896b704a7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["(707703, 51)\n"]}],"source":["print(train_data_final.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1749887585251,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"},"user_tz":-330},"id":"NkedRujBsszJ","outputId":"4f69eaa7-b819-4a35-97b6-ae4619619cfe"},"outputs":[{"output_type":"stream","name":"stdout","text":["(43716, 51)\n"]}],"source":["print(test_data_final.shape)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59,"status":"ok","timestamp":1749887588035,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"},"user_tz":-330},"id":"rG9nZ63MB1rO","outputId":"1e6042ef-d391-41de-f2db-100425948c2b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['HH_ID', 'Person Srl No.', 'Relation to head (code)', 'Gender',\n","       'Age(in years)', 'Marital Status (code)',\n","       'Highest educational level attained (code)',\n","       'Total year of education completed',\n","       'Whether used internet from any location during last 30 days',\n","       'No. of days stayed away from home during last 30 days',\n","       'No. of meals usually taken in a day',\n","       'No. of meals taken during last 30 days from school, balwadi etc.',\n","       'No. of meals taken during last 30 days from employer as perquisites or part of wage',\n","       'No. of meals taken during last 30 days  others',\n","       'No. of meals taken during last 30 days on payment',\n","       'No. of meals taken during last 30 days at home', 'Sector', 'State',\n","       'NSS-Region', 'District', 'Household Type',\n","       'Religion of the head of the household',\n","       'Social Group of the head of the household', 'HH Size (For FDQ)',\n","       'NCO_3D', 'NIC_5D', 'Is_online_Clothing_Purchased_Last365',\n","       'Is_online_Footwear_Purchased_Last365',\n","       'Is_online_Furniture_fixturesPurchased_Last365',\n","       'Is_online_Mobile_Handset_Purchased_Last365',\n","       'Is_online_Personal_Goods_Purchased_Last365',\n","       'Is_online_Recreation_Goods_Purchased_Last365',\n","       'Is_online_Household_Appliances_Purchased_Last365',\n","       'Is_online_Crockery_Utensils_Purchased_Last365',\n","       'Is_online_Sports_Goods_Purchased_Last365',\n","       'Is_online_Medical_Equipment_Purchased_Last365',\n","       'Is_online_Bedding_Purchased_Last365', 'Is_HH_Have_Television',\n","       'Is_HH_Have_Radio', 'Is_HH_Have_Laptop_PC', 'Is_HH_Have_Mobile_handset',\n","       'Is_HH_Have_Bicycle', 'Is_HH_Have_Motorcycle_scooter',\n","       'Is_HH_Have_Motorcar_jeep_van', 'Is_HH_Have_Trucks',\n","       'Is_HH_Have_Animal_cart', 'Is_HH_Have_Refrigerator',\n","       'Is_HH_Have_Washing_machine', 'Is_HH_Have_Airconditioner_aircooler',\n","       'Weight', 'TotalExpense'],\n","      dtype='object')"]},"metadata":{},"execution_count":12}],"source":["train_data_final.columns"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"p0w9yMghDYp0","executionInfo":{"status":"ok","timestamp":1749887626564,"user_tz":-330,"elapsed":144,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}}},"outputs":[],"source":["import pandas as pd\n","\n","# Define the column we want to modify\n","employer_meals_col = 'No. of meals taken during last 30 days from employer as perquisites or part of wage'\n","household_type_col = 'Household Type'  # Adjust if your household type column has a different name\n","\n","# Create a mask for the specified household types (1, 2, 5, and 6)\n","household_mask = train_data_final[household_type_col].isin([1, 2, 5, 6])\n","\n","# Fill missing values with 0 for the specified household types\n","train_data_final.loc[household_mask & train_data_final[employer_meals_col].isna(), employer_meals_col] = 0\n","test_data_final.loc[household_mask & test_data_final[employer_meals_col].isna(), employer_meals_col]=0"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"myyA0f8eEoBM","executionInfo":{"status":"ok","timestamp":1749887630968,"user_tz":-330,"elapsed":152,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}}},"outputs":[],"source":["import pandas as pd\n","\n","# Define the column we want to modify\n","school_meals_col = 'No. of meals taken during last 30 days from school, balwadi etc.'\n","age_col = 'Age(in years)'  # Adjust if your age column has a different name\n","\n","# Create a mask for individuals over 14 years old\n","age_mask = train_data_final[age_col] > 14\n","\n","# Fill missing values with 0 for individuals over 14\n","train_data_final.loc[age_mask & train_data_final[school_meals_col].isna(), school_meals_col] = 0\n","test_data_final.loc[age_mask & test_data_final[school_meals_col].isna(), school_meals_col] =0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"smICQ1oyFuDf"},"outputs":[],"source":["import pandas as pd\n","\n","# Define the column we want to modify\n","payment_meals_col = 'No. of meals taken during last 30 days on payment'\n","sector_col = 'Sector'  # Adjust if your sector column has a different name\n","\n","# Create a mask for sector 1\n","sector_mask = train_data_final[sector_col] == 1\n","\n","# Fill missing values with 0 for sector 1\n","train_data_final.loc[sector_mask & train_data_final[payment_meals_col].isna(), payment_meals_col] = 0\n","test_data_final.loc[sector_mask & test_data_final[payment_meals_col].isna(), payment_meals_col] = 0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X2SjVKsPGk_-","outputId":"e7996244-06ed-4d0b-9332-f74f4fd63be0","executionInfo":{"status":"ok","timestamp":1749716856552,"user_tz":-330,"elapsed":858967,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using 20 feature columns for imputation\n","Imputing categorical column: Whether used internet from any location during last 30 days with 24868 missing values\n","  Unique values: [1. 2.]\n","  Imputation complete for Whether used internet from any location during last 30 days\n","Imputing numeric column: No. of days stayed away from home during last 30 days with 1398 missing values\n","  Imputation complete for No. of days stayed away from home during last 30 days\n","Imputing numeric column: No. of meals usually taken in a day with 1668 missing values\n","  Imputation complete for No. of meals usually taken in a day\n","Imputing numeric column: No. of meals taken during last 30 days from school, balwadi etc. with 89518 missing values\n","  Imputation complete for No. of meals taken during last 30 days from school, balwadi etc.\n","Imputing numeric column: No. of meals taken during last 30 days from employer as perquisites or part of wage with 101913 missing values\n","  Imputation complete for No. of meals taken during last 30 days from employer as perquisites or part of wage\n","Imputing numeric column: No. of meals taken during last 30 days  others with 453640 missing values\n","  Imputation complete for No. of meals taken during last 30 days  others\n","Imputing numeric column: No. of meals taken during last 30 days on payment with 160960 missing values\n","  Imputation complete for No. of meals taken during last 30 days on payment\n","Imputing numeric column: No. of meals taken during last 30 days at home with 4950 missing values\n","  Imputation complete for No. of meals taken during last 30 days at home\n","Successfully imputed all values in Whether used internet from any location during last 30 days\n","Successfully imputed all values in No. of days stayed away from home during last 30 days\n","Successfully imputed all values in No. of meals usually taken in a day\n","Successfully imputed all values in No. of meals taken during last 30 days from school, balwadi etc.\n","Successfully imputed all values in No. of meals taken during last 30 days from employer as perquisites or part of wage\n","Successfully imputed all values in No. of meals taken during last 30 days  others\n","Successfully imputed all values in No. of meals taken during last 30 days on payment\n","Successfully imputed all values in No. of meals taken during last 30 days at home\n","\n","Summary statistics after imputation:\n","\n","Whether used internet from any location during last 30 days value counts:\n","Whether used internet from any location during last 30 days\n","1.0    399907\n","2.0    307796\n","Name: count, dtype: int64\n","\n","Numeric columns statistics:\n","       No. of days stayed away from home during last 30 days  \\\n","count                                      707703.000000       \n","mean                                            0.205263       \n","std                                             1.318225       \n","min                                             0.000000       \n","25%                                             0.000000       \n","50%                                             0.000000       \n","75%                                             0.000000       \n","max                                            30.000000       \n","\n","       No. of meals usually taken in a day  \\\n","count                        707703.000000   \n","mean                              2.558140   \n","std                               0.547055   \n","min                               0.000000   \n","25%                               2.000000   \n","50%                               3.000000   \n","75%                               3.000000   \n","max                               3.000000   \n","\n","       No. of meals taken during last 30 days from school, balwadi etc.  \\\n","count                                      707703.000000                  \n","mean                                            2.082077                  \n","std                                             5.399902                  \n","min                                             0.000000                  \n","25%                                             0.000000                  \n","50%                                             0.000000                  \n","75%                                             0.000000                  \n","max                                            26.000000                  \n","\n","       No. of meals taken during last 30 days from employer as perquisites or part of wage  \\\n","count                                      707703.000000                                     \n","mean                                            0.167905                                     \n","std                                             2.109615                                     \n","min                                             0.000000                                     \n","25%                                             0.000000                                     \n","50%                                             0.000000                                     \n","75%                                             0.000000                                     \n","max                                            90.000000                                     \n","\n","       No. of meals taken during last 30 days  others  \\\n","count                                   707703.000000   \n","mean                                         2.105690   \n","std                                          4.003302   \n","min                                          0.000000   \n","25%                                          1.000000   \n","50%                                          2.000000   \n","75%                                          2.000000   \n","max                                         90.000000   \n","\n","       No. of meals taken during last 30 days on payment  \\\n","count                                      707703.000000   \n","mean                                            1.011693   \n","std                                             5.261961   \n","min                                             0.000000   \n","25%                                             0.000000   \n","50%                                             0.000000   \n","75%                                             0.000000   \n","max                                            90.000000   \n","\n","       No. of meals taken during last 30 days at home  \n","count                                   707703.000000  \n","mean                                        74.213609  \n","std                                         16.745744  \n","min                                         -5.000000  \n","25%                                         60.000000  \n","50%                                         80.000000  \n","75%                                         90.000000  \n","max                                         95.000000  \n","\n","Imputation completed in 842.47 seconds\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","import time\n","\n","# Define the columns to impute\n","categorical_columns = [\n","    'Whether used internet from any location during last 30 days'\n","]\n","\n","numeric_columns = [\n","    'No. of days stayed away from home during last 30 days',\n","    'No. of meals usually taken in a day',\n","    'No. of meals taken during last 30 days from school, balwadi etc.',\n","    'No. of meals taken during last 30 days from employer as perquisites or part of wage',\n","    'No. of meals taken during last 30 days  others',\n","    'No. of meals taken during last 30 days on payment',\n","    'No. of meals taken during last 30 days at home'\n","]\n","\n","# Start timing\n","start_time = time.time()\n","\n","# Verify columns exist\n","categorical_exists = [col for col in categorical_columns if col in train_data_final.columns]\n","numeric_exists = [col for col in numeric_columns if col in train_data_final.columns]\n","\n","all_columns_to_impute = categorical_exists + numeric_exists\n","\n","# Identify feature columns for prediction (exclude columns we're imputing)\n","feature_cols = [col for col in train_data_final.select_dtypes(include=['int64', 'float64']).columns\n","               if col not in all_columns_to_impute]\n","\n","# If we have too many features, we can limit to a subset\n","if len(feature_cols) > 20:\n","    feature_cols = feature_cols[:20]  # Using first 20 as an example\n","\n","print(f\"Using {len(feature_cols)} feature columns for imputation\")\n","\n","# First, impute the categorical column using RandomForestClassifier\n","for col in categorical_exists:\n","    missing_mask = train_data_final[col].isnull()\n","    missing_count = missing_mask.sum()\n","\n","    if missing_count == 0:\n","        print(f\"No missing values in {col}, skipping\")\n","        continue\n","\n","    print(f\"Imputing categorical column: {col} with {missing_count} missing values\")\n","\n","    # Check unique values to ensure it's categorical\n","    unique_values = train_data_final[col].dropna().unique()\n","    print(f\"  Unique values: {unique_values}\")\n","\n","    # Split data into rows with the value (for training) and rows without (to predict)\n","    train_data = train_data_final[~missing_mask]\n","    predict_data = train_data_final[missing_mask]\n","\n","    # Prepare training data\n","    X_train = train_data[feature_cols].fillna(-999)  # Simple handling for missing features\n","    y_train = train_data[col]\n","\n","    # Prepare prediction data\n","    X_predict = predict_data[feature_cols].fillna(-999)\n","\n","    # Train RandomForestClassifier\n","    clf = RandomForestClassifier(\n","        n_estimators=100,\n","        max_depth=5,\n","        random_state=42,\n","        n_jobs=-1  # Use all cores\n","    )\n","\n","    # Train the model\n","    clf.fit(X_train, y_train)\n","\n","    # Predict missing values\n","    predictions = clf.predict(X_predict)\n","\n","    # Fill the missing values with predictions\n","    train_data_final.loc[missing_mask, col] = predictions\n","\n","    print(f\"  Imputation complete for {col}\")\n","\n","# Next, impute the numeric columns using RandomForestRegressor\n","for col in numeric_exists:\n","    missing_mask = train_data_final[col].isnull()\n","    missing_count = missing_mask.sum()\n","\n","    if missing_count == 0:\n","        print(f\"No missing values in {col}, skipping\")\n","        continue\n","\n","    print(f\"Imputing numeric column: {col} with {missing_count} missing values\")\n","\n","    # Split data into rows with the value (for training) and rows without (to predict)\n","    train_data = train_data_final[~missing_mask]\n","    predict_data = train_data_final[missing_mask]\n","\n","    # Prepare training data\n","    X_train = train_data[feature_cols].fillna(-999)\n","    y_train = train_data[col]\n","\n","    # Prepare prediction data\n","    X_predict = predict_data[feature_cols].fillna(-999)\n","\n","    # Train RandomForestRegressor\n","    regr = RandomForestRegressor(\n","        n_estimators=100,\n","        max_depth=5,\n","        random_state=42,\n","        n_jobs=-1  # Use all cores\n","    )\n","\n","    # Train the model\n","    regr.fit(X_train, y_train)\n","\n","    # Predict missing values\n","    predictions = regr.predict(X_predict)\n","\n","    # Round to nearest integer since these are count variables\n","    predictions = np.round(predictions).astype(int)\n","\n","    # Ensure predictions are non-negative\n","    predictions = np.maximum(0, predictions)\n","\n","    # Fill the missing values with predictions\n","    train_data_final.loc[missing_mask, col] = predictions\n","\n","    print(f\"  Imputation complete for {col}\")\n","\n","# End timing\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","\n","# Verify imputation\n","for col in all_columns_to_impute:\n","    missing_values = train_data_final[col].isnull().sum()\n","    if missing_values > 0:\n","        print(f\"Warning: {col} still has {missing_values} missing values after imputation\")\n","    else:\n","        print(f\"Successfully imputed all values in {col}\")\n","\n","# Print summary statistics for the imputed columns\n","print(\"\\nSummary statistics after imputation:\")\n","for col in categorical_exists:\n","    print(f\"\\n{col} value counts:\")\n","    print(train_data_final[col].value_counts())\n","\n","print(\"\\nNumeric columns statistics:\")\n","print(train_data_final[numeric_exists].describe())\n","\n","print(f\"\\nImputation completed in {elapsed_time:.2f} seconds\")\n","train_data_final.to_csv('final_train_dataset.csv', index=False)\n"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","import time\n","import joblib\n","import os\n","\n","def train_imputation_models(train_data):\n","    \"\"\"\n","    Train imputation models on training data and save them\n","\n","    Parameters:\n","    train_data (DataFrame): Training dataset with some values already imputed\n","\n","    Returns:\n","    models_dict (dict): Dictionary containing trained imputation models\n","    feature_cols (list): List of feature columns used for imputation\n","    \"\"\"\n","    # Define the columns to impute\n","    categorical_columns = [\n","        'Whether used internet from any location during last 30 days'\n","    ]\n","\n","    numeric_columns = [\n","        'No. of days stayed away from home during last 30 days',\n","        'No. of meals usually taken in a day',\n","        'No. of meals taken during last 30 days from school, balwadi etc.',\n","        'No. of meals taken during last 30 days from employer as perquisites or part of wage',\n","        'No. of meals taken during last 30 days  others',\n","        'No. of meals taken during last 30 days on payment',\n","        'No. of meals taken during last 30 days at home'\n","    ]\n","\n","    print(\"Training imputation models on training data...\")\n","\n","    # Start timing\n","    start_time = time.time()\n","\n","    # Verify columns exist\n","    categorical_exists = [col for col in categorical_columns if col in train_data.columns]\n","    numeric_exists = [col for col in numeric_columns if col in train_data.columns]\n","\n","    all_columns_to_impute = categorical_exists + numeric_exists\n","\n","    # Identify feature columns for prediction (exclude columns we're imputing)\n","    feature_cols = [col for col in train_data.select_dtypes(include=['int64', 'float64']).columns\n","                   if col not in all_columns_to_impute]\n","\n","    # If we have too many features, we can limit to a subset\n","    if len(feature_cols) > 20:\n","        feature_cols = feature_cols[:20]  # Using first 20 as an example\n","\n","    print(f\"Using {len(feature_cols)} feature columns for imputation\")\n","\n","    # Dictionary to store trained models\n","    imputation_models = {}\n","\n","    # Train models for categorical columns\n","    for col in categorical_exists:\n","        # Check if column has missing values in training data\n","        missing_count = train_data[col].isnull().sum()\n","        if missing_count > 0:\n","            print(f\"Warning: {col} still has {missing_count} missing values in training data\")\n","            continue  # Skip this column since it has missing values\n","\n","        # Check unique values to ensure it's categorical\n","        unique_values = train_data[col].unique()\n","        print(f\"Training imputation model for categorical column: {col}\")\n","        print(f\"  Unique values: {unique_values}\")\n","\n","        # Prepare training data (all rows that have this value)\n","        X_train = train_data[feature_cols].fillna(-999)  # Simple handling for missing features\n","        y_train = train_data[col]\n","\n","        # Train RandomForestClassifier\n","        clf = RandomForestClassifier(\n","            n_estimators=100,\n","            max_depth=5,\n","            random_state=42,\n","            n_jobs=-1  # Use all cores\n","        )\n","\n","        # Train the model\n","        clf.fit(X_train, y_train)\n","\n","        # Store the model\n","        imputation_models[col] = {\n","            'model': clf,\n","            'type': 'classifier'\n","        }\n","\n","        print(f\"  Model trained for {col}\")\n","\n","    # Train models for numeric columns\n","    for col in numeric_exists:\n","        # Check if column has missing values in training data\n","        missing_count = train_data[col].isnull().sum()\n","        if missing_count > 0:\n","            print(f\"Warning: {col} still has {missing_count} missing values in training data\")\n","            continue  # Skip this column since it has missing values\n","\n","        print(f\"Training imputation model for numeric column: {col}\")\n","\n","        # Prepare training data (all rows that have this value)\n","        X_train = train_data[feature_cols].fillna(-999)\n","        y_train = train_data[col]\n","\n","        # Train RandomForestRegressor\n","        regr = RandomForestRegressor(\n","            n_estimators=100,\n","            max_depth=5,\n","            random_state=42,\n","            n_jobs=-1  # Use all cores\n","        )\n","\n","        # Train the model\n","        regr.fit(X_train, y_train)\n","\n","        # Store the model\n","        imputation_models[col] = {\n","            'model': regr,\n","            'type': 'regressor'\n","        }\n","\n","        print(f\"  Model trained for {col}\")\n","\n","    # End timing\n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","    print(f\"Model training completed in {elapsed_time:.2f} seconds\")\n","\n","    # Create models directory if it doesn't exist\n","    if not os.path.exists('models'):\n","        os.makedirs('models')\n","\n","    # Save the models and feature columns\n","    models_dict = {\n","        'imputation_models': imputation_models,\n","        'feature_cols': feature_cols\n","    }\n","\n","    joblib.dump(models_dict, 'models/imputation_models.pkl')\n","    print(\"Imputation models saved to 'models/imputation_models.pkl'\")\n","\n","    return models_dict\n","\n","def impute_test_data(test_data, models_dict=None):\n","    \"\"\"\n","    Apply imputation models to fill missing values in test data\n","\n","    Parameters:\n","    test_data (DataFrame): Test dataset with missing values\n","    models_dict (dict): Dictionary containing trained imputation models\n","\n","    Returns:\n","    test_data_imputed (DataFrame): Test dataset with imputed values\n","    \"\"\"\n","    # Make a copy of the test data\n","    test_data_imputed = test_data.copy()\n","\n","    # Load models if not provided\n","    if models_dict is None:\n","        if os.path.exists('models/imputation_models.pkl'):\n","            print(\"Loading imputation models...\")\n","            models_dict = joblib.load('models/imputation_models.pkl')\n","        else:\n","            raise ValueError(\"Imputation models not found. Please train models first.\")\n","\n","    imputation_models = models_dict['imputation_models']\n","    feature_cols = models_dict['feature_cols']\n","\n","    print(f\"Applying imputation models to test data using {len(feature_cols)} features...\")\n","\n","    # Start timing\n","    start_time = time.time()\n","\n","    # Check which columns we have models for\n","    columns_to_impute = list(imputation_models.keys())\n","\n","    # Verify these columns exist in test data\n","    columns_to_impute = [col for col in columns_to_impute if col in test_data_imputed.columns]\n","\n","    if not columns_to_impute:\n","        print(\"No columns to impute found in the test dataset\")\n","        return test_data_imputed\n","\n","    # Ensure feature columns exist in test data\n","    missing_features = [col for col in feature_cols if col not in test_data_imputed.columns]\n","    if missing_features:\n","        print(f\"Warning: Test data is missing these feature columns: {missing_features}\")\n","        # Only use available features\n","        available_features = [col for col in feature_cols if col in test_data_imputed.columns]\n","        if not available_features:\n","            raise ValueError(\"No usable feature columns found in test data\")\n","        feature_cols = available_features\n","\n","    # Apply imputation for each column\n","    for col in columns_to_impute:\n","        # Check if column has missing values\n","        missing_mask = test_data_imputed[col].isnull()\n","        missing_count = missing_mask.sum()\n","\n","        if missing_count == 0:\n","            print(f\"No missing values in {col}, skipping\")\n","            continue\n","\n","        print(f\"Imputing column: {col} with {missing_count} missing values\")\n","\n","        # Get the appropriate model\n","        model_info = imputation_models[col]\n","        model = model_info['model']\n","        model_type = model_info['type']\n","\n","        # Prepare prediction data\n","        X_predict = test_data_imputed.loc[missing_mask, feature_cols].fillna(-999)\n","\n","        # Predict missing values\n","        predictions = model.predict(X_predict)\n","\n","        # For numeric columns, round to integers and ensure non-negative\n","        if model_type == 'regressor':\n","            predictions = np.round(predictions).astype(int)\n","            predictions = np.maximum(0, predictions)\n","\n","        # Fill the missing values with predictions\n","        test_data_imputed.loc[missing_mask, col] = predictions\n","\n","        print(f\"  Imputation complete for {col}\")\n","\n","    # End timing\n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","\n","    # Verify imputation\n","    for col in columns_to_impute:\n","        missing_values = test_data_imputed[col].isnull().sum()\n","        if missing_values > 0:\n","            print(f\"Warning: {col} still has {missing_values} missing values after imputation\")\n","        else:\n","            print(f\"Successfully imputed all values in {col}\")\n","\n","    print(f\"\\nImputation completed in {elapsed_time:.2f} seconds\")\n","\n","    return test_data_imputed\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","\n","\n","    # Train imputation models on the training data\n","    models_dict = train_imputation_models(train_data_final)\n","\n","    # Apply imputation to test data\n","    test_data_imputed = impute_test_data(test_data_final, models_dict)\n","\n","    # Save the imputed test data\n","    output_path = '/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/final_test_dataset.csv'\n","    test_data_imputed.to_csv(output_path, index=False)\n","    print(f\"Imputed test data saved to {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQHj4L9cfCP9","executionInfo":{"status":"ok","timestamp":1749718077666,"user_tz":-330,"elapsed":1050046,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}},"outputId":"1fa23242-cdd6-4101-9e39-0e5a6d112167"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training imputation models on training data...\n","Using 20 feature columns for imputation\n","Training imputation model for categorical column: Whether used internet from any location during last 30 days\n","  Unique values: [1. 2.]\n","  Model trained for Whether used internet from any location during last 30 days\n","Training imputation model for numeric column: No. of days stayed away from home during last 30 days\n","  Model trained for No. of days stayed away from home during last 30 days\n","Training imputation model for numeric column: No. of meals usually taken in a day\n","  Model trained for No. of meals usually taken in a day\n","Training imputation model for numeric column: No. of meals taken during last 30 days from school, balwadi etc.\n","  Model trained for No. of meals taken during last 30 days from school, balwadi etc.\n","Training imputation model for numeric column: No. of meals taken during last 30 days from employer as perquisites or part of wage\n","  Model trained for No. of meals taken during last 30 days from employer as perquisites or part of wage\n","Training imputation model for numeric column: No. of meals taken during last 30 days  others\n","  Model trained for No. of meals taken during last 30 days  others\n","Training imputation model for numeric column: No. of meals taken during last 30 days on payment\n","  Model trained for No. of meals taken during last 30 days on payment\n","Training imputation model for numeric column: No. of meals taken during last 30 days at home\n","  Model trained for No. of meals taken during last 30 days at home\n","Model training completed in 1048.63 seconds\n","Imputation models saved to 'models/imputation_models.pkl'\n","Applying imputation models to test data using 20 features...\n","Imputing column: Whether used internet from any location during last 30 days with 1494 missing values\n","  Imputation complete for Whether used internet from any location during last 30 days\n","Imputing column: No. of days stayed away from home during last 30 days with 95 missing values\n","  Imputation complete for No. of days stayed away from home during last 30 days\n","Imputing column: No. of meals usually taken in a day with 110 missing values\n","  Imputation complete for No. of meals usually taken in a day\n","Imputing column: No. of meals taken during last 30 days from school, balwadi etc. with 6932 missing values\n","  Imputation complete for No. of meals taken during last 30 days from school, balwadi etc.\n","Imputing column: No. of meals taken during last 30 days from employer as perquisites or part of wage with 6392 missing values\n","  Imputation complete for No. of meals taken during last 30 days from employer as perquisites or part of wage\n","Imputing column: No. of meals taken during last 30 days  others with 28191 missing values\n","  Imputation complete for No. of meals taken during last 30 days  others\n","Imputing column: No. of meals taken during last 30 days on payment with 10815 missing values\n","  Imputation complete for No. of meals taken during last 30 days on payment\n","Imputing column: No. of meals taken during last 30 days at home with 283 missing values\n","  Imputation complete for No. of meals taken during last 30 days at home\n","Successfully imputed all values in Whether used internet from any location during last 30 days\n","Successfully imputed all values in No. of days stayed away from home during last 30 days\n","Successfully imputed all values in No. of meals usually taken in a day\n","Successfully imputed all values in No. of meals taken during last 30 days from school, balwadi etc.\n","Successfully imputed all values in No. of meals taken during last 30 days from employer as perquisites or part of wage\n","Successfully imputed all values in No. of meals taken during last 30 days  others\n","Successfully imputed all values in No. of meals taken during last 30 days on payment\n","Successfully imputed all values in No. of meals taken during last 30 days at home\n","\n","Imputation completed in 0.43 seconds\n","Imputed test data saved to /content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/final_test_dataset.csv\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2a9ogaMQH3PW","outputId":"c64c5b2e-a94c-4699-cec7-b5d486f5362e","executionInfo":{"status":"ok","timestamp":1749718085851,"user_tz":-330,"elapsed":5,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(707703, 51)\n"]}],"source":["print(train_data_final.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VseCSGyVKusm","outputId":"1c007b75-2751-4690-8479-e4e3e2c060e2","executionInfo":{"status":"ok","timestamp":1749718088484,"user_tz":-330,"elapsed":25,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Missing Values in Merged Train Data:\n","HH_ID                                                                                     0\n","Person Srl No.                                                                            0\n","Relation to head (code)                                                                   0\n","Gender                                                                                    0\n","Age(in years)                                                                             0\n","Marital Status (code)                                                                     0\n","Highest educational level attained (code)                                                 0\n","Total year of education completed                                                         0\n","Whether used internet from any location during last 30 days                               0\n","No. of days stayed away from home during last 30 days                                     0\n","No. of meals usually taken in a day                                                       0\n","No. of meals taken during last 30 days from school, balwadi etc.                          0\n","No. of meals taken during last 30 days from employer as perquisites or part of wage       0\n","No. of meals taken during last 30 days  others                                            0\n","No. of meals taken during last 30 days on payment                                         0\n","No. of meals taken during last 30 days at home                                            0\n","Sector                                                                                    0\n","State                                                                                     0\n","NSS-Region                                                                                0\n","District                                                                                  0\n","Household Type                                                                            0\n","Religion of the head of the household                                                     0\n","Social Group of the head of the household                                                 0\n","HH Size (For FDQ)                                                                         0\n","NCO_3D                                                                                 2355\n","NIC_5D                                                                                 2355\n","Is_online_Clothing_Purchased_Last365                                                      0\n","Is_online_Footwear_Purchased_Last365                                                      0\n","Is_online_Furniture_fixturesPurchased_Last365                                             0\n","Is_online_Mobile_Handset_Purchased_Last365                                                0\n","Is_online_Personal_Goods_Purchased_Last365                                                0\n","Is_online_Recreation_Goods_Purchased_Last365                                              0\n","Is_online_Household_Appliances_Purchased_Last365                                          0\n","Is_online_Crockery_Utensils_Purchased_Last365                                             0\n","Is_online_Sports_Goods_Purchased_Last365                                                  0\n","Is_online_Medical_Equipment_Purchased_Last365                                             0\n","Is_online_Bedding_Purchased_Last365                                                       0\n","Is_HH_Have_Television                                                                     0\n","Is_HH_Have_Radio                                                                          0\n","Is_HH_Have_Laptop_PC                                                                      0\n","Is_HH_Have_Mobile_handset                                                                 0\n","Is_HH_Have_Bicycle                                                                        0\n","Is_HH_Have_Motorcycle_scooter                                                             0\n","Is_HH_Have_Motorcar_jeep_van                                                              0\n","Is_HH_Have_Trucks                                                                         0\n","Is_HH_Have_Animal_cart                                                                    0\n","Is_HH_Have_Refrigerator                                                                   0\n","Is_HH_Have_Washing_machine                                                                0\n","Is_HH_Have_Airconditioner_aircooler                                                       0\n","Weight                                                                                    0\n","TotalExpense                                                                              0\n","dtype: int64\n"]}],"source":["print(\"\\nMissing Values in Merged Train Data:\")\n","print(test_data_imputed.isnull().sum())"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Function to calculate weighted expenses for each individual in a family\n","def calculate_weighted_expenses(group):\n","    # Sort adults first (descending by age) so we can assign weights correctly\n","    group = group.sort_values(by='Age(in years)', ascending=False)\n","\n","    # Create weight column based on age\n","    weights = []\n","    adult_count = 0\n","\n","    for age in group['Age(in years)']:\n","        if age > 18:  # Adult\n","            adult_count += 1\n","            if adult_count == 1:\n","                weights.append(1.0)  # First adult\n","            else:\n","                weights.append(0.7)  # Subsequent adults\n","        else:  # Child\n","            weights.append(0.5)\n","\n","    # Add temporary weight column to the group\n","    group['temp_weight'] = weights\n","\n","    # Calculate sum of weights for the family\n","    total_weight = sum(weights)\n","\n","    # Calculate weighted expense for each individual\n","    # Formula: TotalExpense Ã— (individual weight / sum of weights)\n","    total_expense = group['TotalExpense'].iloc[0]  # Assuming TotalExpense is the same for all family members\n","\n","    # Calculate weighted expense for each individual based on their proportion of the total weight\n","    group['WeightedExpense'] = group['temp_weight'].apply(lambda x: total_expense * (x / total_weight))\n","\n","    # Drop the temporary weight column\n","    group = group.drop(columns=['temp_weight'])\n","\n","    return group\n","\n","# Apply the function to create a new dataframe with the calculations\n","result = train_data_final.groupby('HH_ID').apply(calculate_weighted_expenses)\n","\n","# Reset the index to get a clean dataframe\n","if isinstance(result.index, pd.MultiIndex):\n","    result = result.reset_index(drop=True)\n","\n","# Now replace the original dataframe with the updated one\n","train_data_final = result\n","\n","# The train_data_final dataframe now includes the WeightedExpense column\n","\n","# Optional: If you want to verify the changes\n","print(\"Column names in updated dataframe:\", train_data_final.columns.tolist())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X6A3OVEvuvVS","executionInfo":{"status":"ok","timestamp":1749718461345,"user_tz":-330,"elapsed":358085,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}},"outputId":"a294ad6a-348f-471a-911f-c828bd6aca13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-22-2085299322>:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  result = train_data_final.groupby('HH_ID').apply(calculate_weighted_expenses)\n"]},{"output_type":"stream","name":"stdout","text":["Column names in updated dataframe: ['HH_ID', 'Person Srl No.', 'Relation to head (code)', 'Gender', 'Age(in years)', 'Marital Status (code)', 'Highest educational level attained (code)', 'Total year of education completed', 'Whether used internet from any location during last 30 days', 'No. of days stayed away from home during last 30 days', 'No. of meals usually taken in a day', 'No. of meals taken during last 30 days from school, balwadi etc.', 'No. of meals taken during last 30 days from employer as perquisites or part of wage', 'No. of meals taken during last 30 days  others', 'No. of meals taken during last 30 days on payment', 'No. of meals taken during last 30 days at home', 'Sector', 'State', 'NSS-Region', 'District', 'Household Type', 'Religion of the head of the household', 'Social Group of the head of the household', 'HH Size (For FDQ)', 'NCO_3D', 'NIC_5D', 'Is_online_Clothing_Purchased_Last365', 'Is_online_Footwear_Purchased_Last365', 'Is_online_Furniture_fixturesPurchased_Last365', 'Is_online_Mobile_Handset_Purchased_Last365', 'Is_online_Personal_Goods_Purchased_Last365', 'Is_online_Recreation_Goods_Purchased_Last365', 'Is_online_Household_Appliances_Purchased_Last365', 'Is_online_Crockery_Utensils_Purchased_Last365', 'Is_online_Sports_Goods_Purchased_Last365', 'Is_online_Medical_Equipment_Purchased_Last365', 'Is_online_Bedding_Purchased_Last365', 'Is_HH_Have_Television', 'Is_HH_Have_Radio', 'Is_HH_Have_Laptop_PC', 'Is_HH_Have_Mobile_handset', 'Is_HH_Have_Bicycle', 'Is_HH_Have_Motorcycle_scooter', 'Is_HH_Have_Motorcar_jeep_van', 'Is_HH_Have_Trucks', 'Is_HH_Have_Animal_cart', 'Is_HH_Have_Refrigerator', 'Is_HH_Have_Washing_machine', 'Is_HH_Have_Airconditioner_aircooler', 'Weight', 'TotalExpense', 'WeightedExpense']\n"]}]},{"cell_type":"code","source":["# Fill missing values in specific columns with 1000\n","train_data_final[['NCO_3D', 'NIC_5D']] = train_data_final[['NCO_3D', 'NIC_5D']].fillna(1000)\n","test_data_final[['NCO_3D', 'NIC_5D']] = test_data_final[['NCO_3D', 'NIC_5D']].fillna(1000)\n","\n","# Drop 'TotalExpense' column if it exists\n","train_data_final = train_data_final.drop(columns=['TotalExpense'], errors='ignore')\n","# Confirm that there are no more missing values in those columns\n","print(\"Missing values after filling:\")\n","print(train_data_final[['NCO_3D', 'NIC_5D']].isnull().sum())\n","\n","# Save to CSV\n","train_data_final.to_csv(\"/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/train_data_final.csv\", index=False)\n","test_data_final.to_csv(\"/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/test_data_final.csv\", index=False)\n","print(\"Data saved to 'train_data_final.csv'\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MGV8b2fkJpf4","executionInfo":{"status":"ok","timestamp":1749718781811,"user_tz":-330,"elapsed":18146,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}},"outputId":"bc585b2f-f7d7-4a0c-9ddd-af6e606c500a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Missing values after filling:\n","NCO_3D    0\n","NIC_5D    0\n","dtype: int64\n","Data saved to 'train_data_final.csv'\n"]}]},{"cell_type":"code","source":["train_data_final_df = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/train_data_final.csv')\n","test_data_final_df = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/test_data_final.csv')"],"metadata":{"id":"VpiTbJsz79gm","executionInfo":{"status":"ok","timestamp":1749887685001,"user_tz":-330,"elapsed":4471,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["print(train_data_final_df.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gyF2tHa0XlGd","executionInfo":{"status":"ok","timestamp":1749718928990,"user_tz":-330,"elapsed":15,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}},"outputId":"87c02f9a-9fdb-4e3f-9f34-d013ee788fdb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['HH_ID', 'Person Srl No.', 'Relation to head (code)', 'Gender',\n","       'Age(in years)', 'Marital Status (code)',\n","       'Highest educational level attained (code)',\n","       'Total year of education completed',\n","       'Whether used internet from any location during last 30 days',\n","       'No. of days stayed away from home during last 30 days',\n","       'No. of meals usually taken in a day',\n","       'No. of meals taken during last 30 days from school, balwadi etc.',\n","       'No. of meals taken during last 30 days from employer as perquisites or part of wage',\n","       'No. of meals taken during last 30 days  others',\n","       'No. of meals taken during last 30 days on payment',\n","       'No. of meals taken during last 30 days at home', 'Sector', 'State',\n","       'NSS-Region', 'District', 'Household Type',\n","       'Religion of the head of the household',\n","       'Social Group of the head of the household', 'HH Size (For FDQ)',\n","       'NCO_3D', 'NIC_5D', 'Is_online_Clothing_Purchased_Last365',\n","       'Is_online_Footwear_Purchased_Last365',\n","       'Is_online_Furniture_fixturesPurchased_Last365',\n","       'Is_online_Mobile_Handset_Purchased_Last365',\n","       'Is_online_Personal_Goods_Purchased_Last365',\n","       'Is_online_Recreation_Goods_Purchased_Last365',\n","       'Is_online_Household_Appliances_Purchased_Last365',\n","       'Is_online_Crockery_Utensils_Purchased_Last365',\n","       'Is_online_Sports_Goods_Purchased_Last365',\n","       'Is_online_Medical_Equipment_Purchased_Last365',\n","       'Is_online_Bedding_Purchased_Last365', 'Is_HH_Have_Television',\n","       'Is_HH_Have_Radio', 'Is_HH_Have_Laptop_PC', 'Is_HH_Have_Mobile_handset',\n","       'Is_HH_Have_Bicycle', 'Is_HH_Have_Motorcycle_scooter',\n","       'Is_HH_Have_Motorcar_jeep_van', 'Is_HH_Have_Trucks',\n","       'Is_HH_Have_Animal_cart', 'Is_HH_Have_Refrigerator',\n","       'Is_HH_Have_Washing_machine', 'Is_HH_Have_Airconditioner_aircooler',\n","       'Weight', 'WeightedExpense'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["final_train_df = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/final_train_dataset.csv')\n","final_test_df = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/final_test_dataset.csv')\n","print(final_train_df.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M6tPIm7eXl-2","executionInfo":{"status":"ok","timestamp":1749888107186,"user_tz":-330,"elapsed":5742,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}},"outputId":"38901e9a-8b22-4c9b-ca52-58f54694c752"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['HH_ID', 'Person Srl No.', 'Relation to head (code)', 'Gender',\n","       'Age(in years)', 'Marital Status (code)',\n","       'Highest educational level attained (code)',\n","       'Total year of education completed',\n","       'Whether used internet from any location during last 30 days',\n","       'No. of days stayed away from home during last 30 days',\n","       'No. of meals usually taken in a day',\n","       'No. of meals taken during last 30 days from school, balwadi etc.',\n","       'No. of meals taken during last 30 days from employer as perquisites or part of wage',\n","       'No. of meals taken during last 30 days  others',\n","       'No. of meals taken during last 30 days on payment',\n","       'No. of meals taken during last 30 days at home', 'Sector', 'State',\n","       'NSS-Region', 'District', 'Household Type',\n","       'Religion of the head of the household',\n","       'Social Group of the head of the household', 'HH Size (For FDQ)',\n","       'NCO_3D', 'NIC_5D', 'Is_online_Clothing_Purchased_Last365',\n","       'Is_online_Footwear_Purchased_Last365',\n","       'Is_online_Furniture_fixturesPurchased_Last365',\n","       'Is_online_Mobile_Handset_Purchased_Last365',\n","       'Is_online_Personal_Goods_Purchased_Last365',\n","       'Is_online_Recreation_Goods_Purchased_Last365',\n","       'Is_online_Household_Appliances_Purchased_Last365',\n","       'Is_online_Crockery_Utensils_Purchased_Last365',\n","       'Is_online_Sports_Goods_Purchased_Last365',\n","       'Is_online_Medical_Equipment_Purchased_Last365',\n","       'Is_online_Bedding_Purchased_Last365', 'Is_HH_Have_Television',\n","       'Is_HH_Have_Radio', 'Is_HH_Have_Laptop_PC', 'Is_HH_Have_Mobile_handset',\n","       'Is_HH_Have_Bicycle', 'Is_HH_Have_Motorcycle_scooter',\n","       'Is_HH_Have_Motorcar_jeep_van', 'Is_HH_Have_Trucks',\n","       'Is_HH_Have_Animal_cart', 'Is_HH_Have_Refrigerator',\n","       'Is_HH_Have_Washing_machine', 'Is_HH_Have_Airconditioner_aircooler',\n","       'Weight', 'TotalExpense'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["final_test_df = pd.read_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/final_test_dataset.csv')\n","print(final_test_df.columns)\n","print(final_test_df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cariEcSuptZj","executionInfo":{"status":"ok","timestamp":1749891380736,"user_tz":-330,"elapsed":473,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}},"outputId":"68fe5f87-80fd-4028-ab42-bc51282e5f3c"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['HH_ID', 'Person Srl No.', 'Relation to head (code)', 'Gender',\n","       'Age(in years)', 'Marital Status (code)',\n","       'Highest educational level attained (code)',\n","       'Total year of education completed',\n","       'Whether used internet from any location during last 30 days',\n","       'No. of days stayed away from home during last 30 days',\n","       'No. of meals usually taken in a day',\n","       'No. of meals taken during last 30 days from school, balwadi etc.',\n","       'No. of meals taken during last 30 days from employer as perquisites or part of wage',\n","       'No. of meals taken during last 30 days  others',\n","       'No. of meals taken during last 30 days on payment',\n","       'No. of meals taken during last 30 days at home', 'Sector', 'State',\n","       'NSS-Region', 'District', 'Household Type',\n","       'Religion of the head of the household',\n","       'Social Group of the head of the household', 'HH Size (For FDQ)',\n","       'NCO_3D', 'NIC_5D', 'Is_online_Clothing_Purchased_Last365',\n","       'Is_online_Footwear_Purchased_Last365',\n","       'Is_online_Furniture_fixturesPurchased_Last365',\n","       'Is_online_Mobile_Handset_Purchased_Last365',\n","       'Is_online_Personal_Goods_Purchased_Last365',\n","       'Is_online_Recreation_Goods_Purchased_Last365',\n","       'Is_online_Household_Appliances_Purchased_Last365',\n","       'Is_online_Crockery_Utensils_Purchased_Last365',\n","       'Is_online_Sports_Goods_Purchased_Last365',\n","       'Is_online_Medical_Equipment_Purchased_Last365',\n","       'Is_online_Bedding_Purchased_Last365', 'Is_HH_Have_Television',\n","       'Is_HH_Have_Radio', 'Is_HH_Have_Laptop_PC', 'Is_HH_Have_Mobile_handset',\n","       'Is_HH_Have_Bicycle', 'Is_HH_Have_Motorcycle_scooter',\n","       'Is_HH_Have_Motorcar_jeep_van', 'Is_HH_Have_Trucks',\n","       'Is_HH_Have_Animal_cart', 'Is_HH_Have_Refrigerator',\n","       'Is_HH_Have_Washing_machine', 'Is_HH_Have_Airconditioner_aircooler',\n","       'Weight', 'TotalExpense'],\n","      dtype='object')\n","(43716, 51)\n"]}]},{"cell_type":"markdown","source":["# Train File Pre Processing"],"metadata":{"id":"7Iross25qgAq"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","BASE_PERSON_CSV = \"/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/final_train_dataset.csv\"  # still one row per person\n","RAW_PERSON_CSV  = \"/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/person_train.csv\"     # same or another person-level file\n","\n","# â”€â”€â”€ 1. Load the â€œbaseâ€ personâ€‘level file and pull out the HH static cols â”€â”€â”€â”€â”€\n","base = pd.read_csv(BASE_PERSON_CSV)\n","\n","household_static_cols = [\n","    'HH_ID', 'Sector', 'State', 'NSS-Region', 'District',\n","    'Household Type', 'Religion of the head of the household',\n","    'Social Group of the head of the household',\n","    'HH Size (For FDQ)', 'NCO_3D', 'NIC_5D',\n","    # all the onlineâ€purchase flags\n","    'Is_online_Clothing_Purchased_Last365','Is_online_Footwear_Purchased_Last365',\n","    'Is_online_Furniture_fixturesPurchased_Last365','Is_online_Mobile_Handset_Purchased_Last365',\n","    'Is_online_Personal_Goods_Purchased_Last365','Is_online_Recreation_Goods_Purchased_Last365',\n","    'Is_online_Household_Appliances_Purchased_Last365','Is_online_Crockery_Utensils_Purchased_Last365',\n","    'Is_online_Sports_Goods_Purchased_Last365','Is_online_Medical_Equipment_Purchased_Last365',\n","    'Is_online_Bedding_Purchased_Last365',\n","    # all the household asset flags\n","    'Is_HH_Have_Television','Is_HH_Have_Radio','Is_HH_Have_Laptop_PC',\n","    'Is_HH_Have_Mobile_handset','Is_HH_Have_Bicycle','Is_HH_Have_Motorcycle_scooter',\n","    'Is_HH_Have_Motorcar_jeep_van','Is_HH_Have_Trucks','Is_HH_Have_Animal_cart',\n","    'Is_HH_Have_Refrigerator','Is_HH_Have_Washing_machine','Is_HH_Have_Airconditioner_aircooler',\n","    # weights & target\n","    'Weight','TotalExpense'\n","]\n","\n","# Drop all other personâ€‘level columns and then dedupe\n","hh_base = base[household_static_cols].drop_duplicates(subset=\"HH_ID\")\n","\n","# â”€â”€â”€ 2. Load the raw personâ€‘level file for aggregations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","raw = pd.read_csv(RAW_PERSON_CSV)\n","\n","# â”€â”€â”€ 3. Aggregate person-level fields per HH â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# 3a. Age stats\n","agg_age = raw.groupby(\"HH_ID\")[\"Age(in years)\"].agg(\n","    person_count = \"count\",\n","    min_age      = \"min\",\n","    max_age      = \"max\",\n","    avg_age      = \"mean\"\n",")\n","\n","# 3b. Gender counts\n","gender = (\n","    pd.get_dummies(raw[[\"HH_ID\",\"Gender\"]], columns=[\"Gender\"], prefix=\"gender\")\n","      .groupby(\"HH_ID\")\n","      .sum()\n",")\n","gender.rename(columns=lambda c: f\"{c}_count\", inplace=True)\n","\n","# 3c. Education stats\n","agg_edu = raw.groupby(\"HH_ID\")[\"Total year of education completed\"].agg(\n","    avg_education = \"mean\",\n","    max_education = \"max\"\n",")\n","\n","# 3d. Meal stats\n","meal_cols = [\n","    \"No. of meals usually taken in a day\",\n","    \"No. of meals taken during last 30 days from school, balwadi etc.\",\n","    \"No. of meals taken during last 30 days from employer as perquisites or part of wage\",\n","    \"No. of meals taken during last 30 days  others\",\n","    \"No. of meals taken during last 30 days on payment\",\n","    \"No. of meals taken during last 30 days at home\"\n","]\n","agg_meals = raw.groupby(\"HH_ID\")[meal_cols].agg([\"sum\",\"mean\"])\n","agg_meals.columns = [f\"{col}_{fn}\" for col,fn in agg_meals.columns]\n","\n","# 3e. Internet users\n","agg_internet = raw.groupby(\"HH_ID\")[\"Whether used internet from any location during last 30 days\"] \\\n","                  .sum().rename(\"internet_users_count\")\n","\n","# â”€â”€â”€ 4. Combine all aggregated features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","hh_agg = (\n","    agg_age\n","    .join(gender, how=\"left\")\n","    .join(agg_edu, how=\"left\")\n","    .join(agg_meals, how=\"left\")\n","    .join(agg_internet, how=\"left\")\n","    .reset_index()\n",")\n","\n","# â”€â”€â”€ 5. Merge aggregated features back onto static HH base â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","final_train_df = hh_base.merge(hh_agg, on=\"HH_ID\", how=\"left\")\n","\n","# â”€â”€â”€ 6. Reorder columns to exactly your desired schema â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","desired_cols = (\n","    ['HH_ID','Sector','State','NSS-Region','District','Household Type',\n","     'Religion of the head of the household','Social Group of the head of the household',\n","     'HH Size (For FDQ)','NCO_3D','NIC_5D', 'Weight'] +\n","    [col for col in hh_base.columns if col.startswith(\"Is_online_\")] +\n","    [col for col in hh_base.columns if col.startswith(\"Is_HH_Have_\")] +\n","    ['TotalExpense','person_count','avg_age','max_age','min_age',\n","     'gender_1_count','gender_2_count','gender_3_count',\n","     'avg_education','max_education'] +\n","    [f\"{col}_sum\" for col in meal_cols] +\n","    [f\"{col}_mean\" for col in meal_cols] +\n","    ['internet_users_count']\n",")\n","final_train_df = final_train_df[desired_cols]\n","\n","# â”€â”€â”€ 7. Save & sanityâ€check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"Final columns:\", final_train_df.columns.tolist())\n","final_train_df.to_csv(\"/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/final_train_df.csv\", index=False)\n","print(\"âœ” final_train_df.csv saved with exactly the desired features.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FGOTHYvciG9X","executionInfo":{"status":"ok","timestamp":1749977179542,"user_tz":-330,"elapsed":22436,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}},"outputId":"e33c119b-6359-4b9a-971e-7e05e1558ab6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Final columns: ['HH_ID', 'Sector', 'State', 'NSS-Region', 'District', 'Household Type', 'Religion of the head of the household', 'Social Group of the head of the household', 'HH Size (For FDQ)', 'NCO_3D', 'NIC_5D', 'Weight', 'Is_online_Clothing_Purchased_Last365', 'Is_online_Footwear_Purchased_Last365', 'Is_online_Furniture_fixturesPurchased_Last365', 'Is_online_Mobile_Handset_Purchased_Last365', 'Is_online_Personal_Goods_Purchased_Last365', 'Is_online_Recreation_Goods_Purchased_Last365', 'Is_online_Household_Appliances_Purchased_Last365', 'Is_online_Crockery_Utensils_Purchased_Last365', 'Is_online_Sports_Goods_Purchased_Last365', 'Is_online_Medical_Equipment_Purchased_Last365', 'Is_online_Bedding_Purchased_Last365', 'Is_HH_Have_Television', 'Is_HH_Have_Radio', 'Is_HH_Have_Laptop_PC', 'Is_HH_Have_Mobile_handset', 'Is_HH_Have_Bicycle', 'Is_HH_Have_Motorcycle_scooter', 'Is_HH_Have_Motorcar_jeep_van', 'Is_HH_Have_Trucks', 'Is_HH_Have_Animal_cart', 'Is_HH_Have_Refrigerator', 'Is_HH_Have_Washing_machine', 'Is_HH_Have_Airconditioner_aircooler', 'TotalExpense', 'person_count', 'avg_age', 'max_age', 'min_age', 'gender_1_count', 'gender_2_count', 'gender_3_count', 'avg_education', 'max_education', 'No. of meals usually taken in a day_sum', 'No. of meals taken during last 30 days from school, balwadi etc._sum', 'No. of meals taken during last 30 days from employer as perquisites or part of wage_sum', 'No. of meals taken during last 30 days  others_sum', 'No. of meals taken during last 30 days on payment_sum', 'No. of meals taken during last 30 days at home_sum', 'No. of meals usually taken in a day_mean', 'No. of meals taken during last 30 days from school, balwadi etc._mean', 'No. of meals taken during last 30 days from employer as perquisites or part of wage_mean', 'No. of meals taken during last 30 days  others_mean', 'No. of meals taken during last 30 days on payment_mean', 'No. of meals taken during last 30 days at home_mean', 'internet_users_count']\n","âœ” final_train_df.csv saved with exactly the desired features.\n"]}]},{"cell_type":"code","source":["print(final_train_df.shape)\n","print(final_train_df.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GKRz3k8hYj1V","executionInfo":{"status":"ok","timestamp":1749977183616,"user_tz":-330,"elapsed":35,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}},"outputId":"40284b90-8ec6-4be6-b7b7-2e82805d3ae5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(204847, 58)\n","Index(['HH_ID', 'Sector', 'State', 'NSS-Region', 'District', 'Household Type',\n","       'Religion of the head of the household',\n","       'Social Group of the head of the household', 'HH Size (For FDQ)',\n","       'NCO_3D', 'NIC_5D', 'Weight', 'Is_online_Clothing_Purchased_Last365',\n","       'Is_online_Footwear_Purchased_Last365',\n","       'Is_online_Furniture_fixturesPurchased_Last365',\n","       'Is_online_Mobile_Handset_Purchased_Last365',\n","       'Is_online_Personal_Goods_Purchased_Last365',\n","       'Is_online_Recreation_Goods_Purchased_Last365',\n","       'Is_online_Household_Appliances_Purchased_Last365',\n","       'Is_online_Crockery_Utensils_Purchased_Last365',\n","       'Is_online_Sports_Goods_Purchased_Last365',\n","       'Is_online_Medical_Equipment_Purchased_Last365',\n","       'Is_online_Bedding_Purchased_Last365', 'Is_HH_Have_Television',\n","       'Is_HH_Have_Radio', 'Is_HH_Have_Laptop_PC', 'Is_HH_Have_Mobile_handset',\n","       'Is_HH_Have_Bicycle', 'Is_HH_Have_Motorcycle_scooter',\n","       'Is_HH_Have_Motorcar_jeep_van', 'Is_HH_Have_Trucks',\n","       'Is_HH_Have_Animal_cart', 'Is_HH_Have_Refrigerator',\n","       'Is_HH_Have_Washing_machine', 'Is_HH_Have_Airconditioner_aircooler',\n","       'TotalExpense', 'person_count', 'avg_age', 'max_age', 'min_age',\n","       'gender_1_count', 'gender_2_count', 'gender_3_count', 'avg_education',\n","       'max_education', 'No. of meals usually taken in a day_sum',\n","       'No. of meals taken during last 30 days from school, balwadi etc._sum',\n","       'No. of meals taken during last 30 days from employer as perquisites or part of wage_sum',\n","       'No. of meals taken during last 30 days  others_sum',\n","       'No. of meals taken during last 30 days on payment_sum',\n","       'No. of meals taken during last 30 days at home_sum',\n","       'No. of meals usually taken in a day_mean',\n","       'No. of meals taken during last 30 days from school, balwadi etc._mean',\n","       'No. of meals taken during last 30 days from employer as perquisites or part of wage_mean',\n","       'No. of meals taken during last 30 days  others_mean',\n","       'No. of meals taken during last 30 days on payment_mean',\n","       'No. of meals taken during last 30 days at home_mean',\n","       'internet_users_count'],\n","      dtype='object')\n"]}]},{"cell_type":"markdown","source":["# Test File Pre-Processing"],"metadata":{"id":"K3uqwPYAqlLP"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","RAW_TEST_CSV   = \"/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/person_test.csv\"        # your person-level test file\n","BASE_PERSON_CSV= \"/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/final_test_dataset.csv\"           # static HH columns (no TotalExpense)\n","OUTPUT_TEST_HH = \"/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/final_test_df.csv\"\n","\n","# â”€â”€â”€ 1. Load raw test and base HH static file â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","raw = pd.read_csv(RAW_TEST_CSV)\n","base = pd.read_csv(BASE_PERSON_CSV)   # contains HH_ID + all static cols, no TotalExpense\n","\n","# If base still has TotalExpense or Income_Class, drop them:\n","# for c in [\"TotalExpense\",\"Income_Class\"]:\n","#     if c in base.columns:\n","#         base = base.drop(columns=[c])\n","\n","# â”€â”€â”€ 2. PERSON COUNTS & AGE STATS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","agg_age = raw.groupby(\"HH_ID\")[\"Age(in years)\"].agg(\n","    person_count = \"count\",\n","    min_age      = \"min\",\n","    max_age      = \"max\",\n","    avg_age      = \"mean\"\n",")\n","\n","# â”€â”€â”€ 3. GENDER COUNTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","gender = (\n","    pd.get_dummies(raw[[\"HH_ID\",\"Gender\"]], columns=[\"Gender\"], prefix=\"gender\")\n","      .groupby(\"HH_ID\")\n","      .sum()\n",")\n","gender.rename(columns=lambda c: f\"{c}_count\", inplace=True)\n","\n","# â”€â”€â”€ 4. EDUCATION STATS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","agg_edu = raw.groupby(\"HH_ID\")[\"Total year of education completed\"].agg(\n","    avg_education = \"mean\",\n","    max_education = \"max\"\n",")\n","\n","# â”€â”€â”€ 5. MEAL AGGREGATIONS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","meal_cols = [\n","    \"No. of meals usually taken in a day\",\n","    \"No. of meals taken during last 30 days from school, balwadi etc.\",\n","    \"No. of meals taken during last 30 days from employer as perquisites or part of wage\",\n","    \"No. of meals taken during last 30 days  others\",\n","    \"No. of meals taken during last 30 days on payment\",\n","    \"No. of meals taken during last 30 days at home\"\n","]\n","agg_meals = raw.groupby(\"HH_ID\")[meal_cols].agg([\"sum\",\"mean\"])\n","agg_meals.columns = [f\"{col}_{fn}\" for col, fn in agg_meals.columns]\n","\n","# â”€â”€â”€ 6. INTERNET USER COUNT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","agg_internet = raw.groupby(\"HH_ID\")[\"Whether used internet from any location during last 30 days\"] \\\n","                  .sum().rename(\"internet_users_count\")\n","\n","# â”€â”€â”€ 7. COMBINE ALL AGGREGATES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","hh_agg = (\n","    agg_age\n","    .join(gender, how=\"left\")\n","    .join(agg_edu, how=\"left\")\n","    .join(agg_meals, how=\"left\")\n","    .join(agg_internet, how=\"left\")\n","    .reset_index()\n",")\n","\n","# â”€â”€â”€ 8. MERGE INTO BASE HH STATIC FRAME â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","test_features = base.merge(hh_agg, on=\"HH_ID\", how=\"left\")\n","\n","# â”€â”€â”€ 9. Ensure final column order matches train (minus TotalExpense,Income_Class) â”€\n","desired_order = [\n","    'HH_ID', 'Sector', 'State', 'NSS-Region', 'District', 'Household Type',\n","    'Religion of the head of the household', 'Social Group of the head of the household',\n","    'HH Size (For FDQ)', 'NCO_3D', 'NIC_5D',\n","    # online-purchase flags\n","    'Is_online_Clothing_Purchased_Last365','Is_online_Footwear_Purchased_Last365',\n","    'Is_online_Furniture_fixturesPurchased_Last365','Is_online_Mobile_Handset_Purchased_Last365',\n","    'Is_online_Personal_Goods_Purchased_Last365','Is_online_Recreation_Goods_Purchased_Last365',\n","    'Is_online_Household_Appliances_Purchased_Last365','Is_online_Crockery_Utensils_Purchased_Last365',\n","    'Is_online_Sports_Goods_Purchased_Last365','Is_online_Medical_Equipment_Purchased_Last365',\n","    'Is_online_Bedding_Purchased_Last365',\n","    # household assets\n","    'Is_HH_Have_Television','Is_HH_Have_Radio','Is_HH_Have_Laptop_PC','Is_HH_Have_Mobile_handset',\n","    'Is_HH_Have_Bicycle','Is_HH_Have_Motorcycle_scooter','Is_HH_Have_Motorcar_jeep_van',\n","    'Is_HH_Have_Trucks','Is_HH_Have_Animal_cart','Is_HH_Have_Refrigerator',\n","    'Is_HH_Have_Washing_machine','Is_HH_Have_Airconditioner_aircooler',\n","    'person_count','min_age','max_age','avg_age',\n","    'gender_1_count','gender_2_count','gender_3_count',\n","    'avg_education','max_education'\n","] + [f\"{col}_sum\" for col in meal_cols] + [f\"{col}_mean\" for col in meal_cols] + [\n","    'internet_users_count','TotalExpense', 'Weight'\n","]\n","\n","# Final selection (any extras from base that you still need can be inserted manually)\n","final_test_df = test_features[desired_order]\n","\n","# â”€â”€â”€ 10. Save â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","final_test_df.to_csv(OUTPUT_TEST_HH, index=False)\n","print(f\"âœ” Saved test features to {OUTPUT_TEST_HH}\")\n","print(\"Columns now:\", test_features.columns.tolist())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"viQxReXtqpNp","executionInfo":{"status":"ok","timestamp":1749977525916,"user_tz":-330,"elapsed":4137,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}},"outputId":"b581af2f-ee40-4e21-9a64-89ca6d0cffd7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ” Saved test features to /content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/final_test_df.csv\n","Columns now: ['HH_ID', 'Person Srl No.', 'Relation to head (code)', 'Gender', 'Age(in years)', 'Marital Status (code)', 'Highest educational level attained (code)', 'Total year of education completed', 'Whether used internet from any location during last 30 days', 'No. of days stayed away from home during last 30 days', 'No. of meals usually taken in a day', 'No. of meals taken during last 30 days from school, balwadi etc.', 'No. of meals taken during last 30 days from employer as perquisites or part of wage', 'No. of meals taken during last 30 days  others', 'No. of meals taken during last 30 days on payment', 'No. of meals taken during last 30 days at home', 'Sector', 'State', 'NSS-Region', 'District', 'Household Type', 'Religion of the head of the household', 'Social Group of the head of the household', 'HH Size (For FDQ)', 'NCO_3D', 'NIC_5D', 'Is_online_Clothing_Purchased_Last365', 'Is_online_Footwear_Purchased_Last365', 'Is_online_Furniture_fixturesPurchased_Last365', 'Is_online_Mobile_Handset_Purchased_Last365', 'Is_online_Personal_Goods_Purchased_Last365', 'Is_online_Recreation_Goods_Purchased_Last365', 'Is_online_Household_Appliances_Purchased_Last365', 'Is_online_Crockery_Utensils_Purchased_Last365', 'Is_online_Sports_Goods_Purchased_Last365', 'Is_online_Medical_Equipment_Purchased_Last365', 'Is_online_Bedding_Purchased_Last365', 'Is_HH_Have_Television', 'Is_HH_Have_Radio', 'Is_HH_Have_Laptop_PC', 'Is_HH_Have_Mobile_handset', 'Is_HH_Have_Bicycle', 'Is_HH_Have_Motorcycle_scooter', 'Is_HH_Have_Motorcar_jeep_van', 'Is_HH_Have_Trucks', 'Is_HH_Have_Animal_cart', 'Is_HH_Have_Refrigerator', 'Is_HH_Have_Washing_machine', 'Is_HH_Have_Airconditioner_aircooler', 'Weight', 'TotalExpense', 'person_count', 'min_age', 'max_age', 'avg_age', 'gender_1_count', 'gender_2_count', 'gender_3_count', 'avg_education', 'max_education', 'No. of meals usually taken in a day_sum', 'No. of meals usually taken in a day_mean', 'No. of meals taken during last 30 days from school, balwadi etc._sum', 'No. of meals taken during last 30 days from school, balwadi etc._mean', 'No. of meals taken during last 30 days from employer as perquisites or part of wage_sum', 'No. of meals taken during last 30 days from employer as perquisites or part of wage_mean', 'No. of meals taken during last 30 days  others_sum', 'No. of meals taken during last 30 days  others_mean', 'No. of meals taken during last 30 days on payment_sum', 'No. of meals taken during last 30 days on payment_mean', 'No. of meals taken during last 30 days at home_sum', 'No. of meals taken during last 30 days at home_mean', 'internet_users_count']\n"]}]},{"cell_type":"code","source":["print(final_test_df.shape)\n","print(final_test_df.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iOF5muaDrGSO","executionInfo":{"status":"ok","timestamp":1749977546240,"user_tz":-330,"elapsed":97,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}},"outputId":"b56c534e-49d0-4eee-bcef-a9a58aa651d1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["(43716, 58)\n","Index(['HH_ID', 'Sector', 'State', 'NSS-Region', 'District', 'Household Type',\n","       'Religion of the head of the household',\n","       'Social Group of the head of the household', 'HH Size (For FDQ)',\n","       'NCO_3D', 'NIC_5D', 'Is_online_Clothing_Purchased_Last365',\n","       'Is_online_Footwear_Purchased_Last365',\n","       'Is_online_Furniture_fixturesPurchased_Last365',\n","       'Is_online_Mobile_Handset_Purchased_Last365',\n","       'Is_online_Personal_Goods_Purchased_Last365',\n","       'Is_online_Recreation_Goods_Purchased_Last365',\n","       'Is_online_Household_Appliances_Purchased_Last365',\n","       'Is_online_Crockery_Utensils_Purchased_Last365',\n","       'Is_online_Sports_Goods_Purchased_Last365',\n","       'Is_online_Medical_Equipment_Purchased_Last365',\n","       'Is_online_Bedding_Purchased_Last365', 'Is_HH_Have_Television',\n","       'Is_HH_Have_Radio', 'Is_HH_Have_Laptop_PC', 'Is_HH_Have_Mobile_handset',\n","       'Is_HH_Have_Bicycle', 'Is_HH_Have_Motorcycle_scooter',\n","       'Is_HH_Have_Motorcar_jeep_van', 'Is_HH_Have_Trucks',\n","       'Is_HH_Have_Animal_cart', 'Is_HH_Have_Refrigerator',\n","       'Is_HH_Have_Washing_machine', 'Is_HH_Have_Airconditioner_aircooler',\n","       'person_count', 'min_age', 'max_age', 'avg_age', 'gender_1_count',\n","       'gender_2_count', 'gender_3_count', 'avg_education', 'max_education',\n","       'No. of meals usually taken in a day_sum',\n","       'No. of meals taken during last 30 days from school, balwadi etc._sum',\n","       'No. of meals taken during last 30 days from employer as perquisites or part of wage_sum',\n","       'No. of meals taken during last 30 days  others_sum',\n","       'No. of meals taken during last 30 days on payment_sum',\n","       'No. of meals taken during last 30 days at home_sum',\n","       'No. of meals usually taken in a day_mean',\n","       'No. of meals taken during last 30 days from school, balwadi etc._mean',\n","       'No. of meals taken during last 30 days from employer as perquisites or part of wage_mean',\n","       'No. of meals taken during last 30 days  others_mean',\n","       'No. of meals taken during last 30 days on payment_mean',\n","       'No. of meals taken during last 30 days at home_mean',\n","       'internet_users_count', 'TotalExpense', 'Weight'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["# Merge final_train_df and final_test_df and save the merged df to CSV file\n","\n","import pandas as pd\n","# Merge final_train_df and final_test_df\n","merged_final_df = pd.concat([final_train_df, final_test_df], ignore_index=True)\n","\n","# Save the merged DataFrame to a CSV file\n","merged_final_df.to_csv('/content/drive/MyDrive/MPCE_MoSPI/HCES2023-24/merged_final_data.csv', index=False)\n","\n","print(\"Merged final train and test data saved to 'merged_final_data.csv'\")\n","print(\"Shape of the merged dataframe:\", merged_final_df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQtiE8fhYuGO","executionInfo":{"status":"ok","timestamp":1749977574661,"user_tz":-330,"elapsed":9734,"user":{"displayName":"Shubham Pundhir","userId":"15328808238323862706"}},"outputId":"3ba2135c-a514-4bd4-cb68-0c2071191722"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Merged final train and test data saved to 'merged_final_data.csv'\n","Shape of the merged dataframe: (248563, 58)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"03ddWdT8ZExR"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1s-ndP6TAhP8C0ltEjighaZwhSwxocwcL","timestamp":1749701775761}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}